{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the tweepy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tweepy\n",
    "# !pip install mysqlclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import MySQLdb\n",
    "\n",
    "\n",
    "# For sentiment analysis of tweets\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Tweeter Consumer Keys and Access Tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'NFIO7bIgwQpdCZ7p7rgewKXss'\n",
    "consumer_secret= '2QegNrIpcGCW6nCWFTL5JEsrDCmYZpQHJ8SdIT7V0ql5cQgFwV'\n",
    "access_token= '3049227557-36ln3qak9xbxHvgNos45cf3uScGxuUdaDAR4vqs'\n",
    "access_token_secret= 'pZ4Y0p31graKrAYAy41mYztvIrYFzof7awiTDWQr2ui9u'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize AuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define search words and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"#Covid\"\n",
    "date_since = \"2018-11-16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search, q=search_words, lang=\"en\", since=date_since).items(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.cursor.ItemIterator at 0x133e2766240>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through tweets using for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-07 17:03:03\n",
      "17:03:03\n",
      "00:12:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from email.utils import parsedate_tz\n",
    "\n",
    "s='Mon Dec 07 17:03:03 +0000 2020'\n",
    "def to_datetime(datestring):\n",
    "    time_tuple = parsedate_tz(datestring.strip())\n",
    "    dt = datetime(*time_tuple[:6])\n",
    "    return dt - timedelta(seconds=time_tuple[-1])\n",
    "\n",
    "print(to_datetime(s))\n",
    "print(to_datetime(s).time().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "x=datetime.strptime('12/31/13 00:12', \"%m/%j/%y %H:%M\").time().strftime(\"%H:%M:%S\")\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve tweets as a collection of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#UK dreams for getting rid of #covid-19! https://t.co/NaHURX2nVc',\n",
       " 'RT @VABVOX: If you were looking for the worst people in Congress, they are:\\n▪Marsha Blackburn \\n▪Ted Cruz\\n▪Ron Johnson\\n▪Mike Lee\\n▪Rand Paul…',\n",
       " 'RT @NWT_CPHO: THREAD 1/2 – The #CovidAlert App is LIVE in #NWT. By exchanging anonymous Bluetooth codes with nearby phones, the app can tel…',\n",
       " \"Latest news on #RohitSharma\\n\\n #Sydney #Covid cluster unlikely to affect #Rohit's participation \\n\\n@CricCrazyJohns… https://t.co/rXvTYbNmdm\",\n",
       " 'Look at this idiot, trying to take credit for #Covid vaccine that be initially called a hoax https://t.co/kisQR0ry7A']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search Tweets without Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_search = search_words + \" -filter:retweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Covid -filter:retweets'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search, q=new_search, lang=\"en\",since=date_since).items(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Latest news on #RohitSharma\\n\\n #Sydney #Covid cluster unlikely to affect #Rohit's participation \\n\\n@CricCrazyJohns… https://t.co/rXvTYbNmdm\",\n",
       " 'Look at this idiot, trying to take credit for #Covid vaccine that be initially called a hoax https://t.co/kisQR0ry7A',\n",
       " 'Why are we shipping money to Pakistan when Americans are starving because of the #COVID shutdowns? #stimulus',\n",
       " '@WhiteHouse We should have gotten a #COVID19 vaccine sooner but \\n@realDonaldTrump downplayed the dangers of #COVID… https://t.co/7nVYadq0kq',\n",
       " 'Markets fall as more nations join #UK travel ban over #Covid variant; lorry drivers stranded, supermarkets warn of… https://t.co/CjmEs9hRoq']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get username and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search,q=new_search, lang=\"en\", since=date_since).items(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_locs = [[tweet.user.screen_name,tweet.user.location,tweet.text] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Being_SAi143',\n",
       "  'мuмвɑᎥ',\n",
       "  \"Latest news on #RohitSharma\\n\\n #Sydney #Covid cluster unlikely to affect #Rohit's participation \\n\\n@CricCrazyJohns… https://t.co/rXvTYbNmdm\"],\n",
       " ['dangainor',\n",
       "  'Reston, VA.',\n",
       "  'Why are we shipping money to Pakistan when Americans are starving because of the #COVID shutdowns? #stimulus'],\n",
       " ['soloyochapin',\n",
       "  'Chicago, IL',\n",
       "  '@WhiteHouse We should have gotten a #COVID19 vaccine sooner but \\n@realDonaldTrump downplayed the dangers of #COVID… https://t.co/7nVYadq0kq'],\n",
       " ['Diplomacy140',\n",
       "  'London, England',\n",
       "  'Markets fall as more nations join #UK travel ban over #Covid variant; lorry drivers stranded, supermarkets warn of… https://t.co/CjmEs9hRoq'],\n",
       " ['The_Truth_II',\n",
       "  'Praia da Luz,  Portugal ',\n",
       "  'How long are we prepared to live like this? #covid #lockdown #tiersystem #masks #housearrest #roadblocks… https://t.co/phIYFc9jvw']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas Dataframe From A List of Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame(data=users_locs, columns=['user', \"location\",\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Being_SAi143</td>\n",
       "      <td>мuмвɑᎥ</td>\n",
       "      <td>Latest news on #RohitSharma\\n\\n #Sydney #Covid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dangainor</td>\n",
       "      <td>Reston, VA.</td>\n",
       "      <td>Why are we shipping money to Pakistan when Ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soloyochapin</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>@WhiteHouse We should have gotten a #COVID19 v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diplomacy140</td>\n",
       "      <td>London, England</td>\n",
       "      <td>Markets fall as more nations join #UK travel b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The_Truth_II</td>\n",
       "      <td>Praia da Luz,  Portugal</td>\n",
       "      <td>How long are we prepared to live like this? #c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user                  location  \\\n",
       "0  Being_SAi143                    мuмвɑᎥ   \n",
       "1     dangainor               Reston, VA.   \n",
       "2  soloyochapin               Chicago, IL   \n",
       "3  Diplomacy140           London, England   \n",
       "4  The_Truth_II  Praia da Luz,  Portugal    \n",
       "\n",
       "                                               tweet  \n",
       "0  Latest news on #RohitSharma\\n\\n #Sydney #Covid...  \n",
       "1  Why are we shipping money to Pakistan when Ame...  \n",
       "2  @WhiteHouse We should have gotten a #COVID19 v...  \n",
       "3  Markets fall as more nations join #UK travel b...  \n",
       "4  How long are we prepared to live like this? #c...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With The Twitter Streaming API\n",
    "\n",
    "With Streaming data we need to do the following:\n",
    "1. Create database connection\n",
    "2. Create a persistent connection to the Twitter API, and read each connection incrementally.\n",
    "3. Process tweets quickly, store them in the database, and don’t let your program get backed up.\n",
    "4. Handle errors and other issues properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to MySql Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                           (server,MySQL username,MySQL pass, Database name).\n",
    "connection = MySQLdb.connect(\"localhost\",\"root\",\"root\",\"social_analytic\")\n",
    "cur = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StreamListener Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import tweepy\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "search_val=\"covid\"\n",
    "\n",
    "class listener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "       \n",
    "        try:\n",
    "#             tweet_count=0\n",
    "            \n",
    "            all_data = json.loads(data)\n",
    "            \n",
    "#             search_val=\"covid\"\n",
    "            tweet_id=all_data[\"id\"]\n",
    "            created_at=to_datetime(all_data[\"created_at\"])\n",
    "            created_at_date=created_at.date()\n",
    "            created_at_hour=created_at.time().strftime(\"%H\")\n",
    "            created_at_min=created_at.time().strftime(\"%H:%M\")\n",
    "            text = all_data[\"text\"]\n",
    "            source = all_data[\"source\"]\n",
    "#             local_created_at=created_at.str.replace(tzinfo=timezone.utc).astimezone(tz=None)\n",
    "            local_created_at=all_data[\"created_at\"]\n",
    "            \n",
    "            in_reply_to_status_id=all_data['in_reply_to_status_id_str']\n",
    "            in_reply_to_user_id=all_data['in_reply_to_user_id_str']\n",
    "            in_reply_to_screen_name=all_data['in_reply_to_screen_name']\n",
    "            username=all_data['user']['name']\n",
    "            user_screen_name=all_data['user']['screen_name']\n",
    "            user_location=all_data['user']['location']\n",
    "            user_url=all_data['user']['url']\n",
    "            user_description=all_data['user']['description']\n",
    "            user_verified_str=all_data['user']['verified']\n",
    "            user_verified=0\n",
    "            if user_verified_str==True:\n",
    "                user_verified=1\n",
    "            user_followers_count=all_data['user']['followers_count']\n",
    "            user_friends_count=all_data['user']['friends_count']\n",
    "            user_listed_count=all_data['user']['listed_count']\n",
    "            user_favourites_count=all_data['user']['favourites_count']\n",
    "            user_created_at=to_datetime(all_data['user']['created_at'])\n",
    "            user_created_at_date=user_created_at.date()\n",
    "            user_id=all_data['user']['id']\n",
    "            user_profile_image_url_https=all_data['user']['profile_image_url_https']\n",
    "            \n",
    "#             coordinates_lat=all_data['coordinates'][0]\n",
    "#             coordinates_lon=all_data['coordinates'][1]\n",
    "            if all_data['coordinates']==True:\n",
    "                coordinates_lat=all_data['coordinates'][0]\n",
    "                coordinates_lon=all_data['coordinates'][1]\n",
    "            else:\n",
    "                coordinates_lat=None\n",
    "                coordinates_lon=None\n",
    "            if all_data['place']==True:\n",
    "                place_country=all_data['place_country']\n",
    "                place_country_code=all_data['place_country_code']\n",
    "                place_full_name=all_data['place_full_name']\n",
    "                place_id=all_data['place_id']\n",
    "                place_type=all_data['place_type']\n",
    "            else:\n",
    "                place_country=None\n",
    "                place_country_code=None\n",
    "                place_full_name=None\n",
    "                place_id=None\n",
    "                place_type=None\n",
    "                \n",
    "            retweeted_status=None\n",
    "            \n",
    "            if all_data['is_quote_status']==True:\n",
    "                quoted_status_id=all_data['quoted_status_id']\n",
    "                quoted_status=all_data['quoted_status']\n",
    "#                 retweeted_status=all_data['retweeted_status']\n",
    "                quote_count=0\n",
    "            else:\n",
    "                quoted_status_id=None\n",
    "                quote_count=0\n",
    "                quoted_status=None\n",
    "#                 retweeted_status=None\n",
    "            try:\n",
    "                reply_count=all_data['reply_count']\n",
    "            except:\n",
    "                reply_count=0\n",
    "\n",
    "            retweet_count=all_data['retweet_count']\n",
    "            favorite_count=all_data['favorite_count']\n",
    "            retweeted_txt=all_data['retweeted']\n",
    "            entities=str(all_data['entities'])\n",
    "            retweeted=0\n",
    "            if retweeted_txt==True:\n",
    "                retweeted=1\n",
    "#             feeds_link=all_data['https://twitter.com/_/status/'+id]\n",
    "            feeds_link=None\n",
    "            lang=all_data['lang']\n",
    "            feeds_image=None\n",
    "            feeds_video=None\n",
    "            # clean text\n",
    "            text_preprocess = lambda x: re.compile('\\#').sub('', re.compile('RT @').sub('@', x).strip())\n",
    "            clean_text=text_preprocess(text)\n",
    "            clean_text=re.sub('@[^\\s]+','',clean_text)\n",
    "            clean_text=re.sub(r\"http\\S+\", \"\", clean_text)\n",
    "            # end clean text\n",
    "            text_sentiment_polarity=TextBlob(clean_text).sentiment[0]\n",
    "            text_sentiment_subjectivity=TextBlob(clean_text).sentiment[1]\n",
    "\n",
    "\n",
    "            cur.execute(\"INSERT INTO tweet (search_val,  created_at, created_at_date,created_at_hour,created_at_min, tweet_id,  text, source,in_reply_to_status_id, in_reply_to_user_id,  in_reply_to_screen_name,  user_name,  user_screen_name,  user_location, user_url,  user_description, user_verified, user_followers_count,  user_friends_count, user_listed_count,  user_favourites_count,  user_created_at,user_created_at_date, user_id,  user_profile_image_url_https,  coordinates_lat,  coordinates_lon, place_country,  place_country_code,  place_full_name, place_id,  place_type,  quoted_status_id,  quoted_status, retweeted_status,  quote_count,  reply_count,  retweet_count,  favorite_count, retweeted,  entities,  lang, feeds_link,  feeds_video, feeds_image,clean_text,text_sentiment_polarity,text_sentiment_subjectivity) VALUES (%s, %s,%s, %s,%s, %s,%s,%s,%s, %s, %s, %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\", \n",
    "                        (search_val,created_at,created_at_date,created_at_hour,created_at_min,tweet_id,text,source,in_reply_to_status_id,in_reply_to_user_id,in_reply_to_screen_name,username,user_screen_name,user_location,user_url,user_description,user_verified,user_followers_count,user_friends_count,user_listed_count,user_favourites_count,user_created_at,user_created_at_date,user_id,user_profile_image_url_https,coordinates_lat,coordinates_lon,place_country,place_country_code,place_full_name,place_id,place_type,quoted_status_id,quoted_status,retweeted_status,quote_count,reply_count,retweet_count,favorite_count,retweeted,entities,lang,feeds_link,feeds_video,feeds_image,clean_text,text_sentiment_polarity,text_sentiment_subjectivity))\n",
    "\n",
    "            connection.commit()\n",
    "            print(\"Fetched tweets ...........\\n\",text)\n",
    "            print(created_at_hour,created_at_min)\n",
    "#             tweet_count +=1\n",
    "\n",
    "            return True\n",
    "\n",
    "# Catch all the errors from Database or Twiteer\n",
    "        except tweepy.error.TweepError:\n",
    "            print(\"Error fetching the data\")\n",
    "            \n",
    "        except UnicodeEncodeError:\n",
    "            pass\n",
    "        \n",
    "        except MySQLdb.DataError as e:\n",
    "            print(\"DataError\")\n",
    "            print(e)\n",
    "\n",
    "        except MySQLdb.InternalError as e:\n",
    "            print(\"InternalError\")\n",
    "            print(e)\n",
    "\n",
    "        except MySQLdb.IntegrityError as e:\n",
    "            print(\"IntegrityError\")\n",
    "            print(e)\n",
    "\n",
    "        except MySQLdb.OperationalError as e:\n",
    "            print(\"OperationalError\")\n",
    "            print(e)\n",
    "\n",
    "        except MySQLdb.NotSupportedError as e:\n",
    "            print(\"NotSupportedError\")\n",
    "            print(e)\n",
    "\n",
    "        except MySQLdb.ProgrammingError as e:\n",
    "            print(\"ProgrammingError\")\n",
    "            print(e)\n",
    "        except:\n",
    "            print (\"Unexpected general error: \", sys.exc_info()[0])\n",
    "            raise\n",
    "        finally:\n",
    "            print(\"  \")\n",
    "            #             cur.close()\n",
    "            #             connection.close()\n",
    "            \n",
    "\n",
    "    def on_error(self, status):\n",
    "        print (status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
