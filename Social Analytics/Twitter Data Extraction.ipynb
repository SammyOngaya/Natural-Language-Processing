{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the tweepy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tweepy\n",
    "# !pip install mysqlclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import re\n",
    "\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "from geopandas.tools import geocode\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import MySQLdb\n",
    "\n",
    "\n",
    "# For sentiment analysis of tweets\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Tweeter Consumer Keys and Access Tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= 'NFIO7bIgwQpdCZ7p7rgewKXss'\n",
    "consumer_secret= '2QegNrIpcGCW6nCWFTL5JEsrDCmYZpQHJ8SdIT7V0ql5cQgFwV'\n",
    "access_token= '3049227557-36ln3qak9xbxHvgNos45cf3uScGxuUdaDAR4vqs'\n",
    "access_token_secret= 'pZ4Y0p31graKrAYAy41mYztvIrYFzof7awiTDWQr2ui9u'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize AuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define search words and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"#Covid\"\n",
    "date_since = \"2018-11-16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search, q=search_words, lang=\"en\", since=date_since).items(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.cursor.ItemIterator at 0x1c6fde10d30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through tweets using for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-07 17:03:03\n",
      "2021-03-19 19:14:28\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from email.utils import parsedate_tz\n",
    "\n",
    "s='Mon Dec 07 17:03:03 +0000 2020'\n",
    "def to_datetime(datestring):\n",
    "    time_tuple = parsedate_tz(datestring.strip())\n",
    "    dt = datetime(*time_tuple[:6])\n",
    "    proper_date=(dt - timedelta(seconds=time_tuple[-1]))\n",
    "    return proper_date\n",
    "\n",
    "print(to_datetime(s))\n",
    "\n",
    "dt_string = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve tweets as a collection of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search Tweets without Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_search = search_words \n",
    "# + \" -filter:retweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Covid'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search, q=new_search, lang=\"en\",since=date_since).items(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @vineetbhola90: Germany allowed its states to open their schools and KGs from mid Feb (CW7 for Saxony, CW8 for some other states)\\n5-9 Y…',\n",
       " '#MIT Engineers Develop a Cheap Ventilator for COVID-19 Treatment https://t.co/tuCWX5UglJ #covid #design #event',\n",
       " 'RT @vineetbhola90: Germany allowed its states to open their schools and KGs from mid Feb (CW7 for Saxony, CW8 for some other states)\\n5-9 Y…',\n",
       " 'RT @DrNinaRadcliff: In #Israel they have a #vaccine #passport that allows #vaccinated people access to #gyms #restaurants #hotels #concerts…',\n",
       " 'RT @TorontoWriter: Dr Coleman listing deaths by experimental #Covid injection shot.\\n\\n#coronavirus #health #medtwitter #vaxxed #lockdowns #p…',\n",
       " 'RT @drrajivguptaias: .@AmdavadAMC will start super spreaders’ #COVID testing at multiple locations in city from tomorrow.Home delivery staf…',\n",
       " 'RT @AZKARKOUR: First #business trip in #COVID times since March 2020 leading me to #Romania with a magic drive in snow from #Bucharest to c…',\n",
       " 'RT @BenMarten: The ultimate goalpost is 7b people vaccinated. That’s 7b*40$=280b$. Pfizer’s annual revenue is 40b$!\\nIt’s clear that this is…',\n",
       " 'RT @DrRPNishank: #COVID-19 vaccine is absolutely safe and efficacious.\\nSenior citizens &amp; people with comorbidities in the age bracket of 45…',\n",
       " 'RT @SpokespersonCHN: The #US values &amp; rules are not international values &amp; rules. With its ugly #humanrights records &amp; 500k-plus #COVID dea…']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get username and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search,q=new_search, lang=\"en\", since=date_since).items(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # clean text\n",
    "text_preprocess = lambda x: re.compile('\\#').sub('', re.compile('RT @').sub('@', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created_at=to_datetime(all_data[\"created_at\"])\n",
    "#             created_at_date=created_at.date()\n",
    "\n",
    "users_locs = [[tweet.user.screen_name,tweet.user.name,tweet.user.verified,\n",
    "         tweet.user.followers_count,tweet.user.friends_count,tweet.user.listed_count,\n",
    "         tweet.retweet_count,tweet.favorite_count,tweet.retweeted,tweet.entities,\n",
    "         tweet.user.favourites_count,\n",
    "         tweet.user.location,tweet.created_at,tweet.text,\n",
    "         re.sub(r\"http\\S+\", \"\", re.sub('@[^\\s]+','',text_preprocess(tweet.text))),\n",
    "         TextBlob(re.sub(r\"http\\S+\", \"\", re.sub('@[^\\s]+','',text_preprocess(tweet.text)))).sentiment[0],\n",
    "         TextBlob(re.sub(r\"http\\S+\", \"\", re.sub('@[^\\s]+','',text_preprocess(tweet.text)))).sentiment[1]\n",
    "              ] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=columns=['screen_name','name','user_verification','followers_count','friends_count',\n",
    "              'listed_count','retweet_count','favorite_count','retweeted','entities','favourites_count',\n",
    "              'location','created_at','text','clean_text','sentiment_polarity','sentiment_subjectivity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas Dataframe From A List of Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame(data=users_locs, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a color column based on sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df[\"sentiment_polarity_color\"] = np.where(tweet_df[\"sentiment_polarity\"]<0, 'red', 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enrich data with geo-coordinates from location names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_geocoder(address):\n",
    "#     try:\n",
    "#         dataframe = geocode(address.strip() , provider=\"nominatim\" , user_agent = 'my_request')\n",
    "#         point = dataframe.geometry.iloc[0]\n",
    "#         return pd.Series({'Latitude': point.y, 'Longitude': point.x})\n",
    "#     except:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_df[['latitude' , 'longitude']]= tweet_df.iloc[:,12].apply( lambda x: custom_geocoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.to_csv(\"tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenizaion(text):\n",
    "    return re.split(' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'current',\n",
       " 'pandemic',\n",
       " 'shows',\n",
       " 'that',\n",
       " 'we',\n",
       " 'can',\n",
       " \"'no\",\n",
       " 'longer',\n",
       " 'ignore',\n",
       " 'the',\n",
       " 'risks']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text=\"The current pandemic shows that we can 'no longer ignore the risks\"\n",
    "text_tokenizaion(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With The Twitter Streaming API\n",
    "\n",
    "With Streaming data we need to do the following:\n",
    "1. Create database connection\n",
    "2. Create a persistent connection to the Twitter API, and read each connection incrementally.\n",
    "3. Process tweets quickly, store them in the database, and don’t let your program get backed up.\n",
    "4. Handle errors and other issues properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to MySql Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(1045, \"Access denied for user 'root'@'localhost' (using password: YES)\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-1311147ab370>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#                           (server,MySQL username,MySQL pass, Database name).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySQLdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"localhost\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"root\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"root\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"social_analytic\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\MySQLdb\\__init__.py\u001b[0m in \u001b[0;36mConnect\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mMySQLdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\MySQLdb\\connections.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mautocommit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"autocommit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursorclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcursorclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (1045, \"Access denied for user 'root'@'localhost' (using password: YES)\")"
     ]
    }
   ],
   "source": [
    "#                           (server,MySQL username,MySQL pass, Database name).\n",
    "connection = MySQLdb.connect(\"localhost\",\"root\",\"root\",\"social_analytic\")\n",
    "cur = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StreamListener Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import tweepy\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "search_val=\"covid\"\n",
    "\n",
    "class listener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "       \n",
    "        try:\n",
    "#             tweet_count=0\n",
    "            \n",
    "            all_data = json.loads(data)\n",
    "            \n",
    "#             search_val=\"covid\"\n",
    "            tweet_id=all_data[\"id\"]\n",
    "            created_at=to_datetime(all_data[\"created_at\"])\n",
    "            created_at_date=created_at.date()\n",
    "            created_at_hour=created_at.time().strftime(\"%H\")\n",
    "            created_at_min=created_at.time().strftime(\"%H:%M\")\n",
    "            text = all_data[\"text\"]\n",
    "            source = all_data[\"source\"]\n",
    "#             local_created_at=created_at.str.replace(tzinfo=timezone.utc).astimezone(tz=None)\n",
    "            local_created_at=all_data[\"created_at\"]\n",
    "        \n",
    "        \n",
    "            in_reply_to_status_id=all_data['in_reply_to_status_id_str']\n",
    "            in_reply_to_user_id=all_data['in_reply_to_user_id_str']\n",
    "            in_reply_to_screen_name=all_data['in_reply_to_screen_name']\n",
    "            username=all_data['user']['name']\n",
    "            user_screen_name=all_data['user']['screen_name']\n",
    "            user_location=all_data['user']['location']\n",
    "            user_url=all_data['user']['url']\n",
    "            user_description=all_data['user']['description']\n",
    "            user_verified_str=all_data['user']['verified']\n",
    "            user_verified=0\n",
    "            if user_verified_str==True:\n",
    "                user_verified=1\n",
    "            user_followers_count=all_data['user']['followers_count']\n",
    "            user_friends_count=all_data['user']['friends_count']\n",
    "            user_listed_count=all_data['user']['listed_count']\n",
    "            user_favourites_count=all_data['user']['favourites_count']\n",
    "            user_created_at=to_datetime(all_data['user']['created_at'])\n",
    "            user_created_at_date=user_created_at.date()\n",
    "            user_id=all_data['user']['id']\n",
    "            user_profile_image_url_https=all_data['user']['profile_image_url_https']\n",
    "            \n",
    "#             coordinates_lat=all_data['coordinates'][0]\n",
    "#             coordinates_lon=all_data['coordinates'][1]\n",
    "            if all_data['coordinates']==True:\n",
    "                coordinates_lat=all_data['coordinates'][0]\n",
    "                coordinates_lon=all_data['coordinates'][1]\n",
    "            else:\n",
    "                coordinates_lat=None\n",
    "                coordinates_lon=None\n",
    "            if all_data['place']==True:\n",
    "                place_country=all_data['place_country']\n",
    "                place_country_code=all_data['place_country_code']\n",
    "                place_full_name=all_data['place_full_name']\n",
    "                place_id=all_data['place_id']\n",
    "                place_type=all_data['place_type']\n",
    "            else:\n",
    "                place_country=None\n",
    "                place_country_code=None\n",
    "                place_full_name=None\n",
    "                place_id=None\n",
    "                place_type=None\n",
    "                \n",
    "            retweeted_status=None\n",
    "            \n",
    "            if all_data['is_quote_status']==True:\n",
    "                quoted_status_id=all_data['quoted_status_id']\n",
    "                quoted_status=all_data['quoted_status']\n",
    "#                 retweeted_status=all_data['retweeted_status']\n",
    "                quote_count=0\n",
    "            else:\n",
    "                quoted_status_id=None\n",
    "                quote_count=0\n",
    "                quoted_status=None\n",
    "#                 retweeted_status=None\n",
    "            try:\n",
    "                reply_count=all_data['reply_count']\n",
    "            except:\n",
    "                reply_count=0\n",
    "            retweet_count=all_data['retweet_count']\n",
    "            favorite_count=all_data['favorite_count']\n",
    "            retweeted_txt=all_data['retweeted']\n",
    "            entities=str(all_data['entities'])\n",
    "            retweeted=0\n",
    "            if retweeted_txt==True:\n",
    "                retweeted=1\n",
    "#             feeds_link=all_data['https://twitter.com/_/status/'+id]\n",
    "            feeds_link=None\n",
    "            lang=all_data['lang']\n",
    "            feeds_image=None\n",
    "            feeds_video=None\n",
    "            # clean text\n",
    "            text_preprocess = lambda x: re.compile('\\#').sub('', re.compile('RT @').sub('@', x).strip())\n",
    "            clean_text=text_preprocess(text)\n",
    "            clean_text=re.sub('@[^\\s]+','',clean_text)\n",
    "            clean_text=re.sub(r\"http\\S+\", \"\", clean_text)\n",
    "            tokenized_text=text_tokenizaion(clean_text)\n",
    "            # end clean text\n",
    "            text_sentiment_polarity=TextBlob(clean_text).sentiment[0]\n",
    "            text_sentiment_subjectivity=TextBlob(clean_text).sentiment[1]\n",
    "\n",
    "\n",
    "            cur.execute(\"INSERT INTO tweet (search_val,  created_at, created_at_date,created_at_hour,created_at_min, tweet_id,  text, source,in_reply_to_status_id, in_reply_to_user_id,  in_reply_to_screen_name,  user_name,  user_screen_name,  user_location, user_url,  user_description, user_verified, user_followers_count,  user_friends_count, user_listed_count,  user_favourites_count,  user_created_at,user_created_at_date, user_id,  user_profile_image_url_https,  coordinates_lat,  coordinates_lon, place_country,  place_country_code,  place_full_name, place_id,  place_type,  quoted_status_id,  quoted_status, retweeted_status,  quote_count,  reply_count,  retweet_count,  favorite_count, retweeted,  entities,  lang, feeds_link,  feeds_video, feeds_image,clean_text,text_sentiment_polarity,text_sentiment_subjectivity) VALUES (%s, %s,%s, %s,%s, %s,%s,%s,%s, %s, %s, %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\", \n",
    "                        (search_val,created_at,created_at_date,created_at_hour,created_at_min,tweet_id,text,source,in_reply_to_status_id,in_reply_to_user_id,in_reply_to_screen_name,username,user_screen_name,user_location,user_url,user_description,user_verified,user_followers_count,user_friends_count,user_listed_count,user_favourites_count,user_created_at,user_created_at_date,user_id,user_profile_image_url_https,coordinates_lat,coordinates_lon,place_country,place_country_code,place_full_name,place_id,place_type,quoted_status_id,quoted_status,retweeted_status,quote_count,reply_count,retweet_count,favorite_count,retweeted,entities,lang,feeds_link,feeds_video,feeds_image,clean_text,text_sentiment_polarity,text_sentiment_subjectivity))\n",
    "\n",
    "            connection.commit()\n",
    "            print(\"Fetched tweets ...........\\n\")\n",
    "            print(created_at,user_created_at)\n",
    "#             tweet_count +=1\n",
    "\n",
    "            return True\n",
    "\n",
    "# Catch all the errors from Database or Twiteer\n",
    "        except tweepy.error.TweepError:\n",
    "            print(\"Error fetching the data\")\n",
    "            \n",
    "        except UnicodeEncodeError:\n",
    "            pass\n",
    "        \n",
    "        except MySQLdb.DataError as e:\n",
    "            print(\"DataError\")\n",
    "            print(e)\n",
    "\n",
    "        except MySQLdb.InternalError as e:\n",
    "            print(\"InternalError\")\n",
    "            print(e)\n",
    "\n",
    "        except MySQLdb.IntegrityError as e:\n",
    "            print(\"IntegrityError\")\n",
    "            print(e)\n",
    "\n",
    "        except MySQLdb.OperationalError as e:\n",
    "            print(\"OperationalError\")\n",
    "            print(e)\n",
    "\n",
    "        except MySQLdb.NotSupportedError as e:\n",
    "            print(\"NotSupportedError\")\n",
    "            print(e)\n",
    "\n",
    "        except MySQLdb.ProgrammingError as e:\n",
    "            print(\"ProgrammingError\")\n",
    "            print(e)\n",
    "        except:\n",
    "            print (\"Unexpected general error: \", sys.exc_info()[0])\n",
    "            raise\n",
    "        finally:\n",
    "            print(\"  \")\n",
    "            #             cur.close()\n",
    "            #             connection.close()\n",
    "            \n",
    "\n",
    "    def on_error(self, status):\n",
    "        print (status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterStream = Stream(auth, listener())\n",
    "twitterStream.filter(track=['covid'],languages = [\"en\"], stall_warnings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
